import json
import logging
from pathlib import Path

import numpy as np
import pandas as pd
from sklearn.metrics import classification_report, confusion_matrix
from sklearn.model_selection import train_test_split
from sklearn.preprocessing import StandardScaler, LabelEncoder
from xgboost import XGBClassifier

# -----------------------------------------------------------------------------
# Paths
# -----------------------------------------------------------------------------
EVENT_OUTCOMES_PATH = "./staging/nasdaq_event_outcomes_v1.parquet"
MASTER_FEATURES_PATH = "./staging/nasdaq_master_features_v1.parquet"

MODEL_PATH = "./models/nasdaq_event_outcome_xgb_v2.pkl"
SCALER_PATH = "./models/nasdaq_event_outcome_scaler_v2.pkl"
FEATURE_LIST_PATH = "./models/nasdaq_event_outcome_features_v2.json"
LABEL_ENCODERS_PATH = "./models/nasdaq_event_outcome_label_encoders_v2.pkl"

RANDOM_STATE = 42
TEST_SIZE = 0.2  # time-split yerine basit holdout; zaman bazlÄ± istersek aÅŸaÄŸÄ±da deÄŸiÅŸtiririz.

# -----------------------------------------------------------------------------
# Logging
# -----------------------------------------------------------------------------
logging.basicConfig(
    level=logging.INFO,
    format="%(asctime)s - %(levelname)s - %(message)s",
)
logger = logging.getLogger("train_event_outcome_v2")


def load_data() -> tuple[pd.DataFrame, pd.DataFrame]:
    logger.info("=" * 78)
    logger.info("ğŸš€ EVENT OUTCOME MODEL v2 TRAINING BAÅLIYOR")
    logger.info("=" * 78)
    logger.info("ğŸ“¥ Event outcomes yÃ¼kleniyor: %s", EVENT_OUTCOMES_PATH)
    events = pd.read_parquet(EVENT_OUTCOMES_PATH)
    logger.info("   âœ… events shape: %s", events.shape)

    logger.info("ğŸ“¥ Master features yÃ¼kleniyor: %s", MASTER_FEATURES_PATH)
    master = pd.read_parquet(MASTER_FEATURES_PATH)
    logger.info("   âœ… master shape: %s", master.shape)

    # timestampâ€™Ä± datetime yap
    events["timestamp"] = pd.to_datetime(events["timestamp"])
    master["timestamp"] = pd.to_datetime(master["timestamp"])

    return events, master


def merge_events_with_features(events: pd.DataFrame, master: pd.DataFrame) -> pd.DataFrame:
    """
    Event outcomes ile master feature'larÄ± timestamp Ã¼zerinden merge eder.
    (Her event iÃ§in aynÄ± barÄ±n tÃ¼m featureâ€™larÄ±nÄ± ekliyoruz.)
    """
    logger.info("ğŸ”— Events + master merge ediliyor (timestamp Ã¼zerinde)...")

    # master sadece feature tarafÄ± (gereksiz kolon varsa atarÄ±z)
    merged = events.merge(master, on="timestamp", how="left", suffixes=("", "_m"))

    logger.info("   âœ… merged shape: %s", merged.shape)
    missing_feat_rows = merged.isna().all(axis=1).sum()
    if missing_feat_rows > 0:
        logger.warning("âš ï¸ %d satÄ±rda tÃ¼m feature'lar NaN (merge sonrasÄ±) â€“ timestamp uyumsuzluÄŸu olabilir.", missing_feat_rows)

    return merged


def prepare_features_and_labels(merged: pd.DataFrame):
    """
    v2 iÃ§in feature matrisi (X) ve label (y) hazÄ±rlar.
    DOWN tarafÄ±nÄ± Ã¶zellikle gÃ¼Ã§lendirmek iÃ§in class aÄŸÄ±rlÄ±klarÄ±nÄ± burada hesaplayacaÄŸÄ±z.
    """
    df = merged.copy()

    # --- Label kolonunu belirle ---
    # future_dir hem numeric hem string olabilir; Ã¶nce string label Ã¼retelim.
    if "future_dir_label" in df.columns:
        y_raw = df["future_dir_label"].astype(str)
    else:
        # future_dir numeric ise onu label'a map'leriz; deÄŸilse string kabul ederiz
        if "future_dir" not in df.columns:
            raise ValueError("âŒ 'future_dir' veya 'future_dir_label' kolonu bulunamadÄ±, label Ã§Ä±karamÄ±yorum.")

        if np.issubdtype(df["future_dir"].dtype, np.number):
            # 0/1/2 gibi ise kaba mapping
            mapping = {0: "CHOP", 1: "UP", 2: "DOWN"}
            y_raw = df["future_dir"].map(mapping).fillna("CHOP").astype(str)
        else:
            # Zaten string ise direkt al
            y_raw = df["future_dir"].astype(str)

    logger.info("   âœ… Label daÄŸÄ±lÄ±mÄ± (y_raw):\n%s", y_raw.value_counts(dropna=False))

    # --- Leakage ve meta kolonlarÄ± exclude list ---
    meta_cols = [
        "timestamp",
    ]

    possible_leak_cols = [
        "future_dir",
        "future_dir_label",
        "tp_sl_result",
        "tp_sl_result_label",
        "max_up_move_pips",
        "max_down_move_pips",
        "p_chop",
        "p_up",
        "p_down",
        "pred_class",
        "pred_label",
        "max_prob",
        "recommendation",
    ]

    leak_cols = [c for c in possible_leak_cols if c in df.columns]

    # Event meta kolonu; ister feature yaparÄ±z ister yapmayÄ±z, ÅŸimdilik kullanmayalÄ±m.
    event_meta_cols = []
    for c in ["event_type", "signal_wave", "signal_wave_label", "tp_pips", "sl_pips", "entry_price"]:
        if c in df.columns:
            event_meta_cols.append(c)

    drop_from_features = set(meta_cols + leak_cols + event_meta_cols)

    # --- Feature kolonlarÄ±nÄ± otomatik seÃ§ (numeric + NaN olmayan yoÄŸun kolonlar) ---
    candidate_features = []
    for c in df.columns:
        if c in drop_from_features:
            continue
        if df[c].dtype == "O":
            # object / stringâ€™leri ÅŸimdilik almÄ±yoruz (v3â€™de target encoding vs yaparÄ±z)
            continue
        candidate_features.append(c)

    # Ã‡ok fazla kolon olabilir; ama problem deÄŸil, XGB bunlarÄ± yer.
    logger.info("   âœ… SeÃ§ilen feature kolon sayÄ±sÄ±: %d", len(candidate_features))

    X = df[candidate_features].copy()

    # Basit missing value imputation
    X = X.replace([np.inf, -np.inf], np.nan)
    X = X.fillna(0.0)

    # Label encode
    le = LabelEncoder()
    y = le.fit_transform(y_raw)

    label_encoders = {"future_dir_label": le, "class_names": list(le.classes_)}

    logger.info("   âœ… Label encoder classes: %s", le.classes_)
    return X, y, candidate_features, label_encoders


def train_model_v2(X: pd.DataFrame, y: np.ndarray, label_encoders: dict):
    """
    XGBClassifier v2 â€“ DOWN sÄ±nÄ±fÄ±nÄ± Ã¶zellikle aÄŸÄ±rlÄ±klandÄ±rÄ±yoruz.
    """
    # Time-base split de yapabiliriz ama basit train_test_split ile baÅŸlayalÄ±m
    X_train, X_valid, y_train, y_valid = train_test_split(
        X, y, test_size=TEST_SIZE, random_state=RANDOM_STATE, shuffle=True
    )

    # Scale
    scaler = StandardScaler()
    X_train_scaled = scaler.fit_transform(X_train)
    X_valid_scaled = scaler.transform(X_valid)

    # Class weight â€“ DOWN'u boost'la
    classes = label_encoders["class_names"]
    # Ã–rn: CHOP:1, UP:1, DOWN:2.5
    base_weights = {cls: 1.0 for cls in classes}
    if "DOWN" in base_weights:
        base_weights["DOWN"] = 2.5

    logger.info("   âœ… Class weights (v2): %s", base_weights)

    # sample_weight vektÃ¶rÃ¼
    inv_map = {cls: idx for idx, cls in enumerate(classes)}
    y_train_labels = np.array([classes[c] for c in y_train])
    sample_weight = np.array([base_weights[label] for label in y_train_labels])

    # Model
    model = XGBClassifier(
        n_estimators=400,
        max_depth=6,
        learning_rate=0.05,
        subsample=0.9,
        colsample_bytree=0.9,
        objective="multi:softprob",
        eval_metric="mlogloss",
        random_state=RANDOM_STATE,
        n_jobs=-1,
    )

    logger.info("ğŸ§  Model eÄŸitimi baÅŸlÄ±yor (v2)...")
    model.fit(X_train_scaled, y_train, sample_weight=sample_weight)

    # Validation raporu
    y_pred = model.predict(X_valid_scaled)
    logger.info("ğŸ“Š CONFUSION MATRIX (v2):\n%s", confusion_matrix(y_valid, y_pred))
    logger.info("ğŸ“Š CLASSIFICATION REPORT (v2):\n%s", classification_report(y_valid, y_pred, target_names=classes))

    return model, scaler


def save_artifacts(model, scaler, feature_list, label_encoders):
    Path("./models").mkdir(exist_ok=True, parents=True)

    import joblib

    joblib.dump(model, MODEL_PATH)
    joblib.dump(scaler, SCALER_PATH)
    joblib.dump(label_encoders, LABEL_ENCODERS_PATH)

    with open(FEATURE_LIST_PATH, "w") as f:
        json.dump(feature_list, f)

    logger.info("ğŸ’¾ Model kaydedildi: %s", MODEL_PATH)
    logger.info("ğŸ’¾ Scaler kaydedildi: %s", SCALER_PATH)
    logger.info("ğŸ’¾ Feature list kaydedildi: %s", FEATURE_LIST_PATH)
    logger.info("ğŸ’¾ Label encoders kaydedildi: %s", LABEL_ENCODERS_PATH)


def main():
    events, master = load_data()
    merged = merge_events_with_features(events, master)
    X, y, feature_list, label_encoders = prepare_features_and_labels(merged)
    model, scaler = train_model_v2(X, y, label_encoders)
    save_artifacts(model, scaler, feature_list, label_encoders)

    logger.info("=" * 78)
    logger.info("âœ… EVENT OUTCOME MODEL v2 TRAINING TAMAMLANDI")
    logger.info("=" * 78)


if __name__ == "__main__":
    main()