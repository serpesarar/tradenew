#!/usr/bin/env python3
import pandas as pd
import numpy as np
from pathlib import Path
import joblib

# ================================
# PATH & PARAMS (GÃœNCEL)
# ================================

# 1) Haber impact event datasÄ±
EVENT_PATH   = "./staging/nasdaq_news_impact_events.parquet"
MODEL_PATH   = "./models/nasdaq_news_impact_dir_xgb.pkl"
SCALER_PATH  = "./models/nasdaq_news_impact_scaler.pkl"
FEATS_PATH   = "./models/nasdaq_news_impact_features.pkl"

# 2) Fiyat + wave + daily macro ana dataset
# ðŸ‘‰ ArtÄ±k BASE_PATH olarak WAVE V3 dosyasÄ±nÄ± kullanÄ±yoruz
BASE_PATH        = "./staging/nasdaq_full_wave_v3.parquet"
WAVE_DATA_PATH   = "./staging/nasdaq_full_wave_v3.parquet"

# 3) Wave direction modeli (v3)
WAVE_MODEL_PATH  = "./models/nasdaq_wave_dir_v3_xgb.pkl"
WAVE_SCALER_PATH = "./models/nasdaq_wave_v3_scaler.pkl"
WAVE_FEATS_PATH  = "./models/nasdaq_wave_v3_features.pkl"

# 4) News impact modeli iÃ§in ayarlar
CONF_THRESH  = 0.75   # news iÃ§in high-confidence eÅŸiÄŸi
PIP_COL      = "fut_pips_mid"
LABEL_COL    = "impact_dir_mid"

# 5) Label mapâ€™ler
LABEL_MAP_NEWS = {
    0: "CHOP",
    1: "BULLISH",
    2: "BEARISH",
}

LABEL_MAP_WAVE = {
    0: "CHOP",
    1: "LONG_WAVE",
    2: "SHORT_WAVE",
}


# ============================================================
# YARDIMCI FONKSÄ°YONLAR
# ============================================================

def load_news_model_and_scaler():
    """News impact modeli + scaler + feature list yÃ¼kler ve boyutlarÄ± dÃ¶ner."""
    if not Path(MODEL_PATH).exists():
        raise FileNotFoundError(f"News modeli yok: {MODEL_PATH}")
    if not Path(SCALER_PATH).exists():
        raise FileNotFoundError(f"News scaler yok: {SCALER_PATH}")
    if not Path(FEATS_PATH).exists():
        raise FileNotFoundError(f"News feature list yok: {FEATS_PATH}")

    model: XGBClassifier = joblib.load(MODEL_PATH)
    scaler = joblib.load(SCALER_PATH)
    feature_list = joblib.load(FEATS_PATH)

    # scaler kaÃ§ feature ile fit edilmiÅŸ
    scaler_n = getattr(scaler, "n_features_in_", len(feature_list))

    # xgboost iÃ§inden gerÃ§ek feature sayÄ±sÄ±
    booster = model.get_booster()
    model_n = int(booster.num_features())

    return model, scaler, feature_list, model_n, scaler_n


def scale_for_model(X: pd.DataFrame, scaler, model_n: int, scaler_n: int) -> np.ndarray:
    """
    Scaler 185, model 184 feature bekliyorsa:
      - Ã¶nce tÃ¼m 185 feature ile scaler.transform
      - sonra X_scaled[:, :model_n] model'e ver
    HiÃ§bir ÅŸeyi silmeyip, sadece X'i doÄŸru ÅŸekle getiriyoruz.
    """
    # scaler input'u scaler_n feature olmalÄ±
    if X.shape[1] != scaler_n:
        # eksik kolonu events'ten zaten yakalamÄ±ÅŸ oluruz, burada sadece assert gibi dÃ¼ÅŸÃ¼n
        raise ValueError(
            f"Scaler {scaler_n} feature bekliyor ama X {X.shape[1]} feature iÃ§eriyor."
        )

    X_scaled_full = scaler.transform(X)  # (N, scaler_n)

    # Model daha az feature bekliyorsa son sÃ¼tunlarÄ± at
    if scaler_n > model_n:
        X_scaled = X_scaled_full[:, :model_n]
    else:
        X_scaled = X_scaled_full

    return X_scaled


def prepare_news_features(events: pd.DataFrame):
    """Event datasÄ±ndan X (news modeli iÃ§in) hazÄ±rlar, scaler + model boyutlarÄ± ile birlikte dÃ¶ner."""
    model, scaler, feature_list, model_n, scaler_n = load_news_model_and_scaler()

    # Feature list tÃ¼m kolonlarda olmalÄ±
    missing_feats = [f for f in feature_list if f not in events.columns]
    if missing_feats:
        raise ValueError(
            f"Event datasÄ±nda eksik feature var (ilk 10): {missing_feats[:10]}"
        )

    X_full = events[feature_list].copy()
    return model, scaler, feature_list, model_n, scaler_n, X_full


# ============================================================
# A) NEWS IMPACT HIGH-CONFIDENCE ANALYSIS
# ============================================================

def run_high_confidence_analysis():
    print("=" * 80)
    print("ðŸš€ NASDAQ NEWS IMPACT HIGH-CONFIDENCE ANALYSIS")
    print("=" * 80)

    # 1) Event data
    if not Path(EVENT_PATH).exists():
        raise FileNotFoundError(f"Event file yok: {EVENT_PATH}")

    events = pd.read_parquet(EVENT_PATH)
    print(f"   âœ… Event data shape: {events.shape}")

    if PIP_COL not in events.columns:
        raise ValueError(f"{PIP_COL} kolonu event datasÄ±nda yok.")

    # 2) Model + scaler + feature list
    model, scaler, feature_list, model_n, scaler_n, X_full = prepare_news_features(events)

    print(f"   âœ… Model yÃ¼klendi: {MODEL_PATH}")
    print(f"   âœ… Scaler yÃ¼klendi: {SCALER_PATH}")
    print(f"   âœ… Feature list yÃ¼klendi: {FEATS_PATH}")
    print(f"   ðŸ”¢ Feature list length (file): {len(feature_list)}")
    print(f"   ðŸ”¢ Model beklenen feature sayÄ±sÄ±: {model_n}")
    print(f"   ðŸ”¢ Scaler beklenen feature sayÄ±sÄ±: {scaler_n}")
    print(f"   âœ… X_full shape (scaler input): {X_full.shape}")

    # 3) Scale + predict_proba
    # Burada hiÃ§bir ÅŸeyi silmiyoruz, sadece scaler+model boyutlarÄ±nÄ± uyumlu hale getiriyoruz
    from sklearn.utils.validation import _is_arraylike_not_scalar  # sadece uyarÄ± iÃ§in (opsiyonel)

    X_scaled = scale_for_model(X_full, scaler, model_n, scaler_n)
    print(f"   âœ… X_scaled shape (model input): {X_scaled.shape}")

    print("\n   ðŸ”® Predict_proba hesaplanÄ±yor...")

    proba = model.predict_proba(X_scaled)
    pred_class = proba.argmax(axis=1)
    max_conf = proba.max(axis=1)

    events["pred_class"] = pred_class
    events["pred_label"] = events["pred_class"].map(LABEL_MAP_NEWS)
    events["pred_conf"] = max_conf

    total_events = len(events)
    hc_mask = events["pred_conf"] >= CONF_THRESH
    hc_events = events[hc_mask].copy()
    hc_n = len(hc_events)

    print(f"\n   ðŸ”¢ Toplam event sayÄ±sÄ±: {total_events:,}")
    print(
        f"   ðŸŽ¯ High-confidence (>= {CONF_THRESH:.2f}) event sayÄ±sÄ±: {hc_n:,} "
        f"({hc_n/total_events*100:.2f}%)"
    )

    # 4) Class bazlÄ± pip istatistikleri
    print("\n" + "-" * 80)
    print("ðŸ“Š HIGH-CONFIDENCE CLASS-BAZLI PIP Ä°STATÄ°STÄ°KLERÄ° (mid horizon)")
    print("-" * 80)

    for cid, name in LABEL_MAP_NEWS.items():
        sub = hc_events[hc_events["pred_class"] == cid]
        if sub.empty:
            print(f"   Class {cid} ({name}): n=0")
            continue

        p50_signed = sub[PIP_COL].quantile(0.5)
        p50_abs = sub[PIP_COL].abs().quantile(0.5)
        p90_abs = sub[PIP_COL].abs().quantile(0.9)

        print(
            f"   Class {cid} ({name}): "
            f"n={len(sub):5d} | "
            f"P50_signed={p50_signed:.1f} pip | "
            f"P50_abs={p50_abs:.1f} pip | "
            f"P90_abs={p90_abs:.1f} pip"
        )

    # 5) Son 5 high-confidence Ã¶rnek
    print("\n" + "-" * 80)
    print("ðŸ§¾ SON 5 HIGH-CONFIDENCE EVENT Ã–RNEÄžÄ°")
    print("-" * 80)

    time_cols = [c for c in ["event_time", "timestamp", "datetime"] if c in hc_events.columns]
    show_cols = []
    if time_cols:
        show_cols.append(time_cols[0])
    show_cols += ["pred_label", "pred_conf", PIP_COL]
    show_cols = [c for c in show_cols if c in hc_events.columns]

    if not hc_events.empty:
        print(
            hc_events.sort_values(time_cols[0] if time_cols else "pred_conf")
                     .tail(5)[show_cols]
        )
    else:
        print("   (High-confidence event yok)")

    print("\n" + "=" * 80)
    print("âœ… NASDAQ NEWS IMPACT HIGH-CONFIDENCE ANALYSIS BÄ°TTÄ°")
    print("=" * 80)

    # SonuÃ§ datasÄ±nÄ± geri dÃ¶ndÃ¼r, signal card tarafÄ±nda kullanacaÄŸÄ±z
    return events, model, scaler, feature_list, model_n, scaler_n


# ============================================================
# B) SIGNAL CARD (SON BAR + SON NEWS)
# ============================================================

def build_nasdaq_signal_card(
    events: pd.DataFrame,
    news_model,
    news_scaler,
    news_feature_list,
    news_model_n: int,
    news_scaler_n: int,
):
    """
    Son M30 bar + son news event iÃ§in:
      - Wave v3 model tahmini
      - News impact model tahmini
      - Kombine bir yorum dÃ¶ner (dict + panel text)
    HiÃ§bir feature veya modeli silmiyoruz; sadece join + hesap yapÄ±yoruz.
    """

    print("\n" + "=" * 80)
    print("ðŸ§ª NASDAQ SIGNAL CARD DEMO (LAST BAR + LAST NEWS)")
    print("=" * 80)

    # ---------- 1) BASE / WAVE TARAFI ----------
    if not Path(BASE_PATH).exists():
        raise FileNotFoundError(f"Base M30 dosyasÄ± yok: {BASE_PATH}")
    if not Path(WAVE_DATA_PATH).exists():
        raise FileNotFoundError(f"Wave v3 data yok: {WAVE_DATA_PATH}")
    if not Path(WAVE_MODEL_PATH).exists():
        raise FileNotFoundError(f"Wave v3 model yok: {WAVE_MODEL_PATH}")
    if not Path(WAVE_SCALER_PATH).exists():
        raise FileNotFoundError(f"Wave v3 scaler yok: {WAVE_SCALER_PATH}")
    if not Path(WAVE_FEATS_PATH).exists():
        raise FileNotFoundError(f"Wave v3 feature list yok: {WAVE_FEATS_PATH}")

    base = pd.read_parquet(BASE_PATH)
    wave_data = pd.read_parquet(WAVE_DATA_PATH)
    wave_model: XGBClassifier = joblib.load(WAVE_MODEL_PATH)
    wave_scaler = joblib.load(WAVE_SCALER_PATH)
    wave_feats = joblib.load(WAVE_FEATS_PATH)

    # timestamp eÅŸleÅŸtirme
    dt_col = None
    for c in ["timestamp", "datetime", "time"]:
        if c in base.columns:
            dt_col = c
            break
    if dt_col is None:
        raise ValueError("Base data iÃ§inde timestamp/datetime yok.")

    base[dt_col] = pd.to_datetime(base[dt_col])
    base = base.sort_values(dt_col).reset_index(drop=True)

    # wave_data'da da datetime/timestamp bul
    wave_dt_col = None
    for c in ["timestamp", "datetime", "time"]:
        if c in wave_data.columns:
            wave_dt_col = c
            break
    if wave_dt_col is None:
        raise ValueError("Wave data iÃ§inde datetime yok.")

    wave_data[wave_dt_col] = pd.to_datetime(wave_data[wave_dt_col])
    wave_data = wave_data.sort_values(wave_dt_col).reset_index(drop=True)

    last_ts = base[dt_col].iloc[-1]
    # en yakÄ±n wave kaydÄ±nÄ± al (<= last_ts)
    wave_last = wave_data[wave_data[wave_dt_col] <= last_ts]
    if wave_last.empty:
        raise ValueError("Wave datasÄ±nda son bara karÅŸÄ±lÄ±k gelen kayÄ±t bulunamadÄ±.")
    wave_last = wave_last.iloc[-1]

    # wave strength & duration
    wave_strength_pips = float(wave_last.get("wave_strength_pips", 0.0))
    wave_duration_bars = float(wave_last.get("wave_duration_bars", 0.0))
    wave_class_id = int(wave_last.get("signal_wave", 0))
    wave_label = LABEL_MAP_WAVE.get(wave_class_id, "CHOP")

    # wave proba iÃ§in modelden geÃ§irelim
    missing_wave_feats = [f for f in wave_feats if f not in base.columns]
    if missing_wave_feats:
        raise ValueError(
            f"Base datasÄ±nda eksik wave feature var (ilk 10): {missing_wave_feats[:10]}"
        )

    X_wave = base[wave_feats].iloc[[-1]].copy()
    X_wave_scaled = wave_scaler.transform(X_wave)
    wave_proba = wave_model.predict_proba(X_wave_scaled)[0]
    wave_conf = float(wave_proba[wave_class_id])

    # crude meta P50/P90 (XAUUSD'deki gibi kalibrasyon yok, ama mantÄ±klÄ± Ã¶lÃ§ek)
    abs_raw = abs(wave_strength_pips)
    meta_p50 = abs_raw * 0.35
    meta_p90 = abs_raw * 0.9
    sign = 0
    if wave_class_id == 1:
        sign = 1
    elif wave_class_id == 2:
        sign = -1

    meta_p50_dir = sign * meta_p50
    meta_p90_dir = sign * meta_p90

    # ---------- 2) NEWS TARAFI ----------
    # Son news event
    news = events.copy()
    # zaman sÃ¼tunu
    news_dt_col = None
    for c in ["event_time", "timestamp", "datetime", "time"]:
        if c in news.columns:
            news_dt_col = c
            break
    if news_dt_col is None:
        raise ValueError("News events iÃ§inde zaman kolonu yok.")

    news[news_dt_col] = pd.to_datetime(news[news_dt_col])
    news = news.sort_values(news_dt_col).reset_index(drop=True)

    news_last = news.iloc[[-1]].copy()

    # X_full (scaler input)
    missing_news_feats = [f for f in news_feature_list if f not in news_last.columns]
    if missing_news_feats:
        raise ValueError(
            f"News event datasÄ±nda eksik feature var (ilk 10): {missing_news_feats[:10]}"
        )

    X_news_full = news_last[news_feature_list].copy()
    X_news_scaled = scale_for_model(X_news_full, news_scaler, news_model_n, news_scaler_n)

    news_proba = news_model.predict_proba(X_news_scaled)[0]
    news_class_id = int(news_proba.argmax())
    news_label = LABEL_MAP_NEWS.get(news_class_id, "CHOP")
    news_conf = float(news_proba[news_class_id])

    fut_pips_mid = float(news_last.get(PIP_COL, np.nan))

    # ---------- 3) KOM BÄ°N E  ----------
    # Kombine confidence text
    if wave_conf >= 0.90 and news_conf >= 0.70:
        combo_conf_text = "YÃœKSEK"
    elif wave_conf >= 0.80 and news_conf >= 0.55:
        combo_conf_text = "ORTA"
    else:
        combo_conf_text = "DÃœÅžÃœK"

    # Kombine target pips: wave P50 yÃ¶nlÃ¼
    combined_target_pips = meta_p50_dir
    combined_p90_pips = meta_p90_dir

    # Panel text (TÃ¼rkÃ§e)
    # dalga sÃ¼resi saat olarak
    wave_hours = wave_duration_bars * 0.5  # 30m bar â†’ 0.5 saat

    # YÃ¶n text
    wave_dir_text = "YUKARI TREND" if wave_class_id == 1 else (
        "AÅžAÄžI TREND" if wave_class_id == 2 else "YATAY/CHOP"
    )

    panel_text = []
    panel_text.append(f"Sinyal (Wave): {wave_label} ({wave_dir_text})")
    panel_text.append(
        f"Tahmini pip hedefi (P50): {combined_target_pips:+.0f} pip "
        f"(P90: {combined_p90_pips:+.0f} pip)"
    )
    panel_text.append(
        f"Tahmini dalga sÃ¼resi: ~{wave_duration_bars:.0f} bar (â‰ˆ {wave_hours:.1f} saat)"
    )
    panel_text.append(f"Wave yÃ¶n gÃ¼veni (model proba): {wave_conf*100:.1f}%")

    panel_text.append("")
    panel_text.append(
        f"Haber etkisi (mid horizon): {news_label} (gÃ¼ven: {news_conf*100:.1f}%)"
    )
    if not np.isnan(fut_pips_mid):
        panel_text.append(
            f"Haber bazlÄ± tipik hareket: gerÃ§ekleÅŸen mid-horizon â‰ˆ {fut_pips_mid:+.1f} pip"
        )
    panel_text.append("")
    panel_text.append(f"Kombine gÃ¼ven yorumu: {combo_conf_text}")
    panel_text.append(f"- Fiyat dalga modeli: {wave_dir_text}")
    panel_text.append(f"- Haber etkisi: {news_label}")

    panel_text_str = "\n".join(panel_text)

    card = {
        "wave": {
            "class_id": wave_class_id,
            "label": wave_label,
            "proba": wave_conf,
            "raw_strength_pips": wave_strength_pips,
            "raw_duration_bars": wave_duration_bars,
            "meta_p50": abs(meta_p50),
            "meta_p90": abs(meta_p90),
        },
        "news": {
            "class_id": news_class_id,
            "label": news_label,
            "confidence": news_conf,
            "fut_pips_mid": fut_pips_mid,
        },
        "combined": {
            "target_pips": combined_target_pips,
            "p90_pips": combined_p90_pips,
            "confidence_text": combo_conf_text,
            "panel_text": panel_text_str,
        },
    }

    print(panel_text_str)
    print("\n--- RAW CARD JSON ---")
    print(card)

    return card


# ============================================================
# MAIN
# ============================================================
if __name__ == "__main__":
    # AÅŸama 1: High-confidence reporting (hiÃ§bir ÅŸeyi kÄ±saltmÄ±yoruz)
    events, news_model, news_scaler, news_feature_list, news_model_n, news_scaler_n = (
        run_high_confidence_analysis()
    )

    # AÅŸama 2: Signal card demo (son bar + son haber)
    card = build_nasdaq_signal_card(
        events=events,
        news_model=news_model,
        news_scaler=news_scaler,
        news_feature_list=news_feature_list,
        news_model_n=news_model_n,
        news_scaler_n=news_scaler_n,
    )